{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZCEkknFNeel5gil/p9rAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhu213/Research-Papers/blob/master/src/RNN_Encoder_Decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from urllib.request import urlopen\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "dVt1h4Hv3PvZ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data"
      ],
      "metadata": {
        "id": "AOcUGyOqIS3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = \"https://raw.githubusercontent.com/suvaansh/Machine-Translation-English-to-Hindi-/master/hin.txt\"\n",
        "\n",
        "with urlopen(link) as url:\n",
        "  temp = url.read().decode('utf-8').split('\\n')\n",
        "  ds = [item.split('\\t') for item in temp]"
      ],
      "metadata": {
        "id": "R0Uv-tgdIAE9"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = ds[:len(ds)-2]"
      ],
      "metadata": {
        "id": "1SwkzFWlTlgQ"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_en(text):\n",
        "  tokenized = re.sub(r'[^\\w\\s+]',' ',text.lower())\n",
        "  return tokenized.split()\n",
        "\n",
        "def tokenize_hi(text):\n",
        "  tokenized = re.sub(r'[!(),-./।:;\"?[\\]^_`{|}~]',' ',text)\n",
        "  return tokenized.split()"
      ],
      "metadata": {
        "id": "5ARTOzVQJuX_"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sanity check\n",
        "print(tokenize_en('He said, \"I will try to get this work done by tomorrow!\"'))\n",
        "print(tokenize_hi('उन्होंने कहा, \"मैं यह काम कल तक पूरा करने की कोशिश करूंगा!\"'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVbFGpJEKgcP",
        "outputId": "9bcd2adf-63bf-4904-8bc8-0eb82e256742"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'said', 'i', 'will', 'try', 'to', 'get', 'this', 'work', 'done', 'by', 'tomorrow']\n",
            "['उन्होंने', 'कहा', 'मैं', 'यह', 'काम', 'कल', 'तक', 'पूरा', 'करने', 'की', 'कोशिश', 'करूंगा']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(iter,lang):\n",
        "  for EN,HI in iter:\n",
        "    if lang is 'en': yield tokenize_en(EN)\n",
        "    else: yield tokenize_hi(HI)"
      ],
      "metadata": {
        "id": "Jdkzx_4hTDeY"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EN_VOCAB = build_vocab_from_iterator(yield_tokens(DATA,'en'),min_freq=2,specials=[\"<unk>\",\"<pad>\",\"<bos>\",\"<eos>\"])\n",
        "EN_VOCAB.set_default_index(0)\n",
        "\n",
        "HI_VOCAB = build_vocab_from_iterator(yield_tokens(DATA,'hi'),min_freq=2,specials=[\"<unk>\",\"<pad>\",\"<bos>\",\"<eos>\"])\n",
        "HI_VOCAB.set_default_index(0)"
      ],
      "metadata": {
        "id": "UluQTv_0Mk0t"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total no. of training examples:\",len(DATA))\n",
        "print(\"English vocab size:\",len(EN_VOCAB))\n",
        "print(\"Hindi vocab size:\",len(HI_VOCAB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Pf82MhMpLu",
        "outputId": "795e7350-8b23-4762-e8cf-a46983e135a0"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of training examples: 2868\n",
            "English vocab size: 1271\n",
            "Hindi vocab size: 1422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_pipeline = lambda x: EN_VOCAB([\"<bos>\",*tokenize_en(x),\"<eos>\"])\n",
        "hi_pipeline = lambda x: HI_VOCAB([\"<bos>\",*tokenize_hi(x),\"<eos>\"])"
      ],
      "metadata": {
        "id": "FbcRPaKxUHKJ"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(data_iter):\n",
        "  src,tgt = [],[]\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  for x,y in data_iter:\n",
        "    src_encoded = en_pipeline(x)\n",
        "    src.append(torch.tensor(src_encoded,dtype=torch.int64,device=device))\n",
        "    tgt_encoded = hi_pipeline(y)\n",
        "    tgt.append(torch.tensor(tgt_encoded,dtype=torch.int64,device=device))\n",
        "  \n",
        "  src = pad_sequence(src,batch_first=True,padding_value=1)\n",
        "  tgt = pad_sequence(tgt,batch_first=True,padding_value=1)\n",
        "  \n",
        "  return src.to(device), tgt.to(device)"
      ],
      "metadata": {
        "id": "uYAl7LVUUmbq"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "TRAIN_DL = DataLoader(DATA,batch_size=BATCH_SIZE,shuffle=True,drop_last=True,collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "5VI-zBggVtF9"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_tensor,hi_tensor = next(iter(TRAIN_DL))\n",
        "print(\"[BATCH_SIZE,en_seq_length]: \",en_tensor.shape)\n",
        "print(\"[BATCH_SIZE,hi_seq_length]: \",hi_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmluYV2WYZ18",
        "outputId": "3b67b14b-83f3-4c10-d5e9-60a7678bbfc8"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BATCH_SIZE,en_seq_length]:  torch.Size([64, 13])\n",
            "[BATCH_SIZE,hi_seq_length]:  torch.Size([64, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "GU_Nn6vaZslZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMBEbH0wZul2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}